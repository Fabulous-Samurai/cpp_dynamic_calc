/**
 * @file eigen_engine.cpp
 * @brief Implementation of high-performance Eigen-based CPU engine
 */

#ifdef ENABLE_EIGEN

#include "eigen_engine.h"
#include <iostream>
#include <sstream>
#include <fstream>
#include <algorithm>
#include <cmath>
#include <random>
#include <thread>
#include <unordered_map>
#include <iomanip>

#ifdef _OPENMP
#include <omp.h>
#endif

namespace OGulator {

EigenEngine::EigenEngine() 
    : optimization_level_(CPUOptimizationLevel::SIMD)
    , simd_enabled_(true)
    , num_threads_(std::thread::hardware_concurrency()) {
    
    // Initialize Eigen with optimal settings for Senna Speed! ðŸŽï¸
    Eigen::initParallel();
    
#ifdef _OPENMP
    if (num_threads_ > 0) {
        Eigen::setNbThreads(num_threads_);
        omp_set_num_threads(num_threads_);
    }
#endif

    // Enable SIMD if available
#ifdef __AVX2__
    EnableAVX2();
#endif
#ifdef __SSE4_1__
    EnableSSE41();
#endif

    ResetMetrics();
    
    std::cout << "ðŸŽï¸ EigenEngine initialized with Senna Speed optimization!" << std::endl;
    std::cout << "   Threads: " << num_threads_ << std::endl;
    std::cout << "   SIMD: " << (simd_enabled_ ? "Enabled" : "Disabled") << std::endl;
}

void EigenEngine::SetOptimizationLevel(CPUOptimizationLevel level) {
    optimization_level_ = level;
    
    switch (level) {
        case CPUOptimizationLevel::Basic:
            simd_enabled_ = false;
            num_threads_ = 1;
            break;
        case CPUOptimizationLevel::SIMD:
            simd_enabled_ = true;
            num_threads_ = 1;
            break;
        case CPUOptimizationLevel::Parallel:
            simd_enabled_ = true;
            num_threads_ = std::thread::hardware_concurrency();
            break;
        case CPUOptimizationLevel::Vectorized:
        case CPUOptimizationLevel::Extreme:
            simd_enabled_ = true;
            num_threads_ = std::thread::hardware_concurrency();
#ifdef _OPENMP
            Eigen::setNbThreads(num_threads_);
#endif
            break;
    }
}

void EigenEngine::SetNumThreads(int num_threads) {
    if (num_threads <= 0) {
        num_threads_ = std::thread::hardware_concurrency();
    } else {
        num_threads_ = num_threads;
    }
    
#ifdef _OPENMP
    Eigen::setNbThreads(num_threads_);
    omp_set_num_threads(num_threads_);
#endif
}

EigenEngine::Matrix EigenEngine::CreateMatrix(const std::vector<std::vector<double>>& data) {
    SENNA_SPEED_EIGEN("CreateMatrix");
    
    if (data.empty()) return Matrix();
    
    size_t rows = data.size();
    size_t cols = data[0].size();
    
    Matrix mat(rows, cols);
    for (size_t i = 0; i < rows; ++i) {
        for (size_t j = 0; j < cols; ++j) {
            mat(i, j) = (j < data[i].size()) ? data[i][j] : 0.0;
        }
    }
    
    return mat;
}

EigenEngine::Vector EigenEngine::CreateVector(const std::vector<double>& data) {
    SENNA_SPEED_EIGEN("CreateVector");
    
    Vector vec(data.size());
    for (size_t i = 0; i < data.size(); ++i) {
        vec(i) = data[i];
    }
    
    return vec;
}

EigenEngine::Matrix EigenEngine::MatrixMultiply(const Matrix& A, const Matrix& B) {
    SENNA_SPEED_EIGEN("MatrixMultiply");
    
    if (optimization_level_ >= CPUOptimizationLevel::Vectorized) {
        return OptimizedMatMul(A, B);
    }
    
    return A * B;
}

EigenEngine::Vector EigenEngine::MatrixVectorMultiply(const Matrix& A, const Vector& x) {
    SENNA_SPEED_EIGEN("MatrixVectorMultiply");
    
    if (optimization_level_ >= CPUOptimizationLevel::Vectorized) {
        return OptimizedMatVecMul(A, x);
    }
    
    return A * x;
}

EigenEngine::Matrix EigenEngine::MatrixAdd(const Matrix& A, const Matrix& B) {
    SENNA_SPEED_EIGEN("MatrixAdd");
    return A + B;
}

EigenEngine::Matrix EigenEngine::MatrixSubtract(const Matrix& A, const Matrix& B) {
    SENNA_SPEED_EIGEN("MatrixSubtract");
    return A - B;
}

double EigenEngine::Determinant(const Matrix& A) {
    SENNA_SPEED_EIGEN("Determinant");
    return A.determinant();
}

EigenEngine::Matrix EigenEngine::Inverse(const Matrix& A) {
    SENNA_SPEED_EIGEN("Inverse");
    
    // Use optimal solver based on matrix properties
    if (A.rows() == A.cols()) {
        // For square matrices, use LU decomposition
        Eigen::FullPivLU<Matrix> lu(A);
        if (lu.isInvertible()) {
            return lu.inverse();
        } else {
            throw std::runtime_error("Matrix is not invertible");
        }
    } else {
        // For non-square matrices, return pseudo-inverse
        return PseudoInverse(A);
    }
}

EigenEngine::Matrix EigenEngine::Transpose(const Matrix& A) {
    SENNA_SPEED_EIGEN("Transpose");
    return A.transpose();
}

EigenEngine::Matrix EigenEngine::PseudoInverse(const Matrix& A) {
    SENNA_SPEED_EIGEN("PseudoInverse");
    
    // Use SVD for numerical stability
    Eigen::JacobiSVD<Matrix> svd(A, Eigen::ComputeFullU | Eigen::ComputeFullV);
    
    const double tolerance = std::numeric_limits<double>::epsilon() * 
                            std::max(A.rows(), A.cols()) * 
                            svd.singularValues().maxCoeff();
    
    return svd.matrixV() * 
           (svd.singularValues().array() > tolerance)
               .select(svd.singularValues().array().inverse(), 0)
               .matrix()
               .asDiagonal() * 
           svd.matrixU().adjoint();
}

std::pair<EigenEngine::Vector, EigenEngine::Matrix> EigenEngine::EigenDecomposition(const Matrix& A) {
    SENNA_SPEED_EIGEN("EigenDecomposition");
    
    if (A.rows() != A.cols()) {
        throw std::runtime_error("Eigendecomposition requires square matrix");
    }
    
    // Check if matrix is symmetric for optimization
    if (A.isApprox(A.transpose())) {
        // Use specialized symmetric solver
        Eigen::SelfAdjointEigenSolver<Matrix> solver(A);
        return {solver.eigenvalues(), solver.eigenvectors()};
    } else {
        // General eigenvalue solver
        Eigen::EigenSolver<Matrix> solver(A);
        return {solver.eigenvalues().real(), solver.eigenvectors().real()};
    }
}

std::pair<EigenEngine::Matrix, EigenEngine::Vector, EigenEngine::Matrix> EigenEngine::SVD(const Matrix& A) {
    SENNA_SPEED_EIGEN("SVD");
    
    Eigen::JacobiSVD<Matrix> svd(A, Eigen::ComputeFullU | Eigen::ComputeFullV);
    return {svd.matrixU(), svd.singularValues(), svd.matrixV()};
}

EigenEngine::Vector EigenEngine::SolveLinearSystem(const Matrix& A, const Vector& b) {
    SENNA_SPEED_EIGEN("SolveLinearSystem");
    
    // Choose optimal solver based on matrix properties
    if (A.rows() == A.cols()) {
        // Square system - check for special properties
        if (A.isApprox(A.transpose()) && A.eigenvalues().real().minCoeff() > 0) {
            // Positive definite - use Cholesky
            Eigen::LLT<Matrix> chol(A);
            if (chol.info() == Eigen::Success) {
                return chol.solve(b);
            }
        }
        
        // General square system - use LU
        Eigen::FullPivLU<Matrix> lu(A);
        return lu.solve(b);
    } else {
        // Overdetermined/underdetermined - use QR
        return A.colPivHouseholderQr().solve(b);
    }
}

EigenEngine::Matrix EigenEngine::SolveMultipleRHS(const Matrix& A, const Matrix& B) {
    SENNA_SPEED_EIGEN("SolveMultipleRHS");
    
    if (A.rows() == A.cols()) {
        Eigen::FullPivLU<Matrix> lu(A);
        return lu.solve(B);
    } else {
        return A.colPivHouseholderQr().solve(B);
    }
}

double EigenEngine::Mean(const Vector& data) {
    SENNA_SPEED_EIGEN("Mean");
    return data.mean();
}

double EigenEngine::StandardDeviation(const Vector& data) {
    SENNA_SPEED_EIGEN("StandardDeviation");
    Vector centered = data.array() - data.mean();
    return std::sqrt(centered.array().square().mean());
}

double EigenEngine::Variance(const Vector& data) {
    SENNA_SPEED_EIGEN("Variance");
    Vector centered = data.array() - data.mean();
    return centered.array().square().mean();
}

EigenEngine::Vector EigenEngine::Normalize(const Vector& data) {
    SENNA_SPEED_EIGEN("Normalize");
    
    double mean_val = data.mean();
    double std_val = StandardDeviation(data);
    
    if (std_val < std::numeric_limits<double>::epsilon()) {
        return Vector::Zero(data.size());
    }
    
    return (data.array() - mean_val) / std_val;
}

std::string EigenEngine::MatrixToString(const Matrix& mat, int precision) const {
    std::stringstream ss;
    ss << std::fixed << std::setprecision(precision);
    
    ss << "Matrix " << mat.rows() << "x" << mat.cols() << ":\n";
    for (int i = 0; i < mat.rows(); ++i) {
        ss << "[ ";
        for (int j = 0; j < mat.cols(); ++j) {
            ss << mat(i, j);
            if (j < mat.cols() - 1) ss << ", ";
        }
        ss << " ]\n";
    }
    
    return ss.str();
}

std::string EigenEngine::VectorToString(const Vector& vec, int precision) const {
    std::stringstream ss;
    ss << std::fixed << std::setprecision(precision);
    
    ss << "Vector " << vec.size() << ":\n[ ";
    for (int i = 0; i < vec.size(); ++i) {
        ss << vec(i);
        if (i < vec.size() - 1) ss << ", ";
    }
    ss << " ]";
    
    return ss.str();
}

void EigenEngine::ResetMetrics() {
    last_metrics_ = CPUPerformanceMetrics();
    last_metrics_.operation_type = "None";
}

std::string EigenEngine::GetPerformanceReport() const {
    std::stringstream ss;
    ss << "ðŸŽï¸ Eigen Engine Performance Report:\n";
    ss << "   Last Operation: " << last_metrics_.operation_type << "\n";
    ss << "   Execution Time: " << last_metrics_.execution_time_ms << " ms\n";
    ss << "   Memory Used: " << last_metrics_.memory_used_bytes << " bytes\n";
    ss << "   SIMD Used: " << (last_metrics_.simd_used ? "Yes" : "No") << "\n";
    ss << "   Optimization Level: ";
    
    switch (optimization_level_) {
        case CPUOptimizationLevel::Basic: ss << "Basic"; break;
        case CPUOptimizationLevel::SIMD: ss << "SIMD"; break;
        case CPUOptimizationLevel::Parallel: ss << "Parallel"; break;
        case CPUOptimizationLevel::Vectorized: ss << "Vectorized"; break;
        case CPUOptimizationLevel::Extreme: ss << "Extreme"; break;
    }
    
    // Performance classification (Senna Speed style!)
    if (last_metrics_.execution_time_ms < 1.0) {
        ss << "\n   ðŸŽï¸ SENNA SPEED: Lightning Fast! (<1ms)";
    } else if (last_metrics_.execution_time_ms < 10.0) {
        ss << "\n   ðŸ FORMULA 1 Speed: Very Fast! (<10ms)";
    } else if (last_metrics_.execution_time_ms < 100.0) {
        ss << "\n   ðŸš— Racing Speed: Fast! (<100ms)";
    } else {
        ss << "\n   ðŸŒ Needs Optimization (>" << last_metrics_.execution_time_ms << "ms)";
    }
    
    return ss.str();
}

// Optimized implementations
EigenEngine::Matrix EigenEngine::OptimizedMatMul(const Matrix& A, const Matrix& B) const {
    // Use Eigen's optimized BLAS if available
    Matrix result = A * B;
    
    // Update metrics to indicate SIMD usage
    const_cast<EigenEngine*>(this)->last_metrics_.simd_used = simd_enabled_;
    
    return result;
}

EigenEngine::Vector EigenEngine::OptimizedMatVecMul(const Matrix& A, const Vector& x) const {
    Vector result = A * x;
    
    // Update metrics
    const_cast<EigenEngine*>(this)->last_metrics_.simd_used = simd_enabled_;
    
    return result;
}

#ifdef __AVX2__
void EigenEngine::EnableAVX2() {
    // AVX2 optimizations would be implemented here
    std::cout << "   ðŸš€ AVX2 SIMD acceleration enabled!" << std::endl;
}
#endif

#ifdef __SSE4_1__
void EigenEngine::EnableSSE41() {
    // SSE4.1 optimizations would be implemented here
    std::cout << "   âš¡ SSE4.1 SIMD acceleration enabled!" << std::endl;
}
#endif

// Performance Timer implementation
PerformanceTimer::PerformanceTimer(const std::string& operation_name)
    : operation_name_(operation_name)
    , start_time_(std::chrono::high_resolution_clock::now()) {
}

PerformanceTimer::~PerformanceTimer() {
    auto end_time = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time_);
    double elapsed_ms = duration.count() / 1000.0;
    
    if (elapsed_ms < 1.0) {
        std::cout << "ðŸŽï¸ " << operation_name_ << ": " << elapsed_ms << "ms (Senna Speed!)" << std::endl;
    }
}

double PerformanceTimer::GetElapsedMs() const {
    auto current_time = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(current_time - start_time_);
    return duration.count() / 1000.0;
}

template<typename Func>
auto EigenEngine::MeasurePerformance(Func&& func, const std::string& operation) const -> decltype(func()) {
    auto start = std::chrono::high_resolution_clock::now();
    
    auto result = func();
    
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    
    const_cast<EigenEngine*>(this)->UpdateMetrics(operation, duration.count() / 1000.0, sizeof(result));
    
    return result;
}

void EigenEngine::UpdateMetrics(const std::string& operation, double time_ms, size_t memory_bytes) const {
    auto* mutable_this = const_cast<EigenEngine*>(this);
    mutable_this->last_metrics_.operation_type = operation;
    mutable_this->last_metrics_.execution_time_ms = time_ms;
    mutable_this->last_metrics_.memory_used_bytes = memory_bytes;
    mutable_this->last_metrics_.simd_used = simd_enabled_;
}

} // namespace OGulator

#endif // ENABLE_EIGEN